Dear Dr. Rácz and Colleagues:

Thank you for submitting your revised manuscript for consideration by Language Learning. We have solicited three external reviews of your paper (two returning, one new), and all of the reviews are now in. As you will see in the detailed reviewer comments, all reviewers found several positive aspects of your study, and I agree with the reviewers that your study features interesting work that will generate follow-up research. Reviewers 1 and 3 (returning) recommended that your manuscript should undergo minor revisions. Reviewer 5 (new), however, returned a ‘Major Revision’ decision. Upon reading the reviewers’ feedback, I agree that there are several aspects of your manuscript that can be improved further. All reviewers commented that are your manuscript is hard to follow, which was a comment expressed not by just a new reviewer but also by both returning reviewers. For example, it is worrisome to me that a reviewer had to look up your previous publication to follow the logic of your experiment and to understand its methods and procedures, and that both returning reviewers commented on how hard it was to follow your research questions, the flow of ideas in the introduction, and the description of the methods. Reviewer 5, who is an expert in statistical modeling, also raised a number of data analysis concerns, which have direct consequences for the findings and their interpretation. My reading of the reviews indicates to me that the extent of the revisions requested by the reviewers will be major in scope and will require some skillful writing/revisions. Therefore, I’d like to invite you to carefully engage with another set of revisions, in order to improve your manuscript further, thus increasing its value for both researchers and students interested in your research area. To describe these revisions, I’ve selected the ‘Major Revision’ option; and I am afraid I would need to involve another set of reviews. To make it easier for reviewers to see your revisions, I would like to ask you to highlight all changes to your manuscript in a different-colour font (e.g., blue) and to clearly summarize all changes in an accompanying letter. In the following notes, I will provide you with some guidance which can help you conceptualize the final revisions to your manuscript.

1. As discussed by all reviewers, improve the flow and the logic of the writing in the introductory section of your manuscript and especially with respect to your research questions. The reviewers indicated that (a) the literature review did not prepare the reader adequately to understand your study, (b) your research questions were unclear, and (c) the overall logic of literature review was hard to follow.

2. As particularly discussed by Reviewers 1 and 5, please ensure that the manuscript reports full methods, materials, and procedure information that would make it a standalone publication and would not require the reader to first consult your previously published work. And again, do provide a clear, coherent account of how the current dataset extends and builds on your previous publication. This information should ideally be used to motivate the current study.

3. Address carefully the Design issues raised by Reviewer 5. I will leave it up to you whether you would wish to remove any data from analysis (point 5 in this reviewer’s feedback), but I strongly encourage you to consider using Levenshtein’s distance between images as a predictor in your analyses (point 6 in this reviewer’s feedback).

4. Most importantly, you must address all statistical/analytical concerns expressed by Reviewer 5 (under Issues with statistical modelling). I find all of these concerns reasonable, and would like to reiterate that reporting effect size values and confidence intervals is mandatory for us (point 5 under statistical/analytical concerns by Reviewer 5).

5. Finally, address all remaining issues by all reviewers.

STATISTICAL GUIDELINES/NONSIGNIFICANT FINDINGS
As a reminder, please prepare the next version of the manuscript in agreement with the Guidelines for Reporting Quantitative Methods and Results in Primary Research as specified on our website (http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-9922/homepage/ForAuthors.html). This includes reporting confidence intervals, effect size values, such as Cohen’s d values for pairwise comparisons, including confidence intervals for effect size values, and test reliability values for all instruments used (where appropriate), as well as making the necessary adjustments for carrying out multiple comparisons (when relevant).

After you have revised your manuscript, please upload the revised version of the manuscript to ScholarOne, along with a detailed bullet-point outline of the changes introduced to the next draft. As I requested you earlier, please designate all revisions in blue font. I very much look forward to reading the revised version of your paper.

Pavel


Reviewer: 1
Recommendation: Minor Revision
Comments to the Author:

This revision is a real improvement on the original submission, and the introduction in particular is much clearer. I nonetheless feel that more work is needed to clarify the method and results, and a little work remains to be done for the introduction too. If this is done, however, I would consider the paper very much worthy of publication.

My first issue with the introduction is that the first research question (“Can we reliably associate any non-linguistic context whatsoever with linguistic constructions?”) still feels too broad considering the question the experiment answers. What exactly is the answer? Do we conclude that for 18% of participants, at least, the answer is yes? (But then, what if there are harder contexts to learn than orientation?) Or do we conclude that, because most participants failed to learn the association with orientation, that it can’t be reliably associated with linguistic constructions? (But then, most participants failed on gender too, and we already know that that can be associated with linguistic constructions.) The second part of the same question (“If not, do our prior expectations regarding what contexts are generally socially relevant play into whether such an association can be established?”)  also seems slightly problematic. I’d agree that participants presumably arrive with prior expectations as to what contexts are generally socially relevant, but that isn’t actually measured here; it’s simply inferred based on what humans seem to associate linguistic constructions to in natural language. The hypotheses given on page 10 seem a much better way to set up the goals of the study.

My other issue is more minor and concerned with how the introduction flows. It’s generally much better, but could still be improved. Two examples stand out. First, the section on contextual learning segues from discussion of context aiding memory to context aiding prediction, to the involvement of context in learning, to the role of context in processing. That’s fine in itself, but the transitions are not quite seamless. For instance, it’s not at all clear in the text how the Qian et al. (2014) study is really a non-linguistic equivalent of the immediately preceding studies. The sociolinguistic learning section has a related but slightly different problem: It feels like a somewhat disjointed list of studies.

The Method and Results sections continue to suffer from problems with clarity.  Part of the problem, I think, is that it feels as if there are two many paragraph breaks, which contributes to a disjointed feel. But there are other problems of unclarity. For instance, on page 10, the conversation partner is introduced in a way that takes the reader by surprise. It would be clearer if the paragraph said something like, “In the first, training phase, a participant has to progress on a path, learning a simple artificial language from [IN ITALICS] conversation partners met along the way. In this language, suffixes that represent a grammatical relation (either the diminutive or the plural) are contextually cued: they depend on the conversation partner, present in each trial.” (Another issue here, incidentally – what precisely constitutes a trial?) There are a few cases like this. I feel as if the Method section would benefit from being reread by someone entirely unfamiliar with the study.  The same problems continue in the Results section, which I found hard to follow. I would suggest the same remedy.

Minor issues (many of which contribute to clarity issues mentioned above):
1. There is a formatting error in the abstract (? instead of, I assume, dashes)
2. The present tense should be replaced by the past tense in many places throughout the manuscript. Its use in reporting published work (e.g., “Docherty, Langstrof, and Foulkes (2013) investigate…”) is common but explicitly discouraged in APA style.  Its use in describing experimental method or reporting results is a little odder and slightly jarring.
3. Page 6: “Speakers of different dialects will focus on and learn different linguistic details (Cohn, Ham, & Podesva, 1999), and speaker awareness of contextual information on all levels can be very imprecise”. This sentence seems to require a “but” not an “and”, as there appears to be a contrast between the two halves. The “and” thus creates a slightly jarring effect.
4. Page 6: “While these factors will have complex social and linguistic representations, they will remain robust and socially salient”. Is there a source for this? 
5. Page 9: A conjunction is missing at least twice (in the first sentence and in the sentence beginning “It utilises…”)
6. Page 9: “adults […] discard contexts that are deemed irrelevant.” By whom? By the adults themselves? I’m also not sure “deem” is the right term here, since (to me at least) it implies conscious deliberation.
7. Page 10: The distinction between “socially salient” and “accidental” seems like a category error. Can’t accidental things be socially salient (and can’t non-accidental things be insalient)?
8. Why is Figure 3 referenced before Figure 1?
9. Page 12: “we repeated two conditions using plural instead of diminutive as the morphological category.” This needs to be clarified! “Repeat” can mean a lot of things. On a related note, the asterisk in Table 2 needs to be explained in the caption.
10. Page 15: “Learning extends to generalisation” seems an odd way to express this.
11. Page 18: “Training is faster with age, ethnicity, and the fastest with gender.” There seems to be a missing conjunction here again.
12. Page 18: “it seems that ignoring the view cue is about as difficult as ignoring the gender cue. I think this would be clearer if something were added along the lines of, “In spite of the differences between the different cues when they were main cues…”
13. The reasoning on pages 21–22 starting with “Second, the overall…” is hard to follow and could do with being clarified.
14. Page 22: I think  “derivative morphology” should be “derivational morphology”. I wonder if perhaps this distinction isn’t in danger of being language-specific. I am unaware of any language in which plural suffixes are derivational and diminutives are inflectional, but this may simply reflect my ignorance. In Welsh, for instance, equivalent forms to passive participles in other languages are formed by a clearly derivational affix, which seems to surprise some people. There are also languages that don’t have inflectional number marking; do some of these have derivational markers used in some cases?
15. Page 23: “for example, in French, incorrect marking of the gender of the addressee in a possessive construction will lead to incomprehension.” Perhaps I am misunderstanding what is being claimed about French, but what I imagine from this example is the contrast between “ton [masc.] cheval” and “ta [f.] voiture”; but this distinction depends on the gender of the possessed, not the addressee.
16. Christiansen and Kirby (2003) was written before the experimental turn in language evolution, and thus seems clearly the wrong citation on page 26. The authors might like to consider (for instance): 
* Scott-Phillips, Thomas C., and Simon Kirby. "Language evolution in the laboratory." Trends in cognitive sciences 14.9 (2010): 411-417.
* Roberts, Gareth. "The linguist’s Drosophila: Experiments in language change." Linguistics Vanguard 3.1 (2017).


Reviewer: 5
Recommendation: Major Revision
Comments to the Author:

Review of manuscript 18-ES-2560.R1

The manuscript addresses an interesting issue in psycholinguistics/sociolinguistics. I am sympathetic with the experimental approach and the task design, and I can overall see good potential in this paper. However, I think there are a number of both major and minor issues with the manuscript (concerning conceptual premises, experimental design, and statistical modelling) that I believe should be solved, before it should be considered for publication. The statistical analyses in particular are quite problematic, as they — in their current form — are very little informative in relation to the hypotheses under scrutiny. I do not feel comfortable in recommending the manuscript for publication until these major concerns with the statistical analyses in particular are solved, especially since implementing some of my suggestions below may change the results drastically. Besides modelling, I have a number of comments pertaining to the general structure and style of the manuscript as well as to the experimental design, which I list below.
Since I am not an expert in sociolinguistic, I will leave it to the other reviewer(s) to comment on whether the revised manuscript addresses the theoretical issues (i.e., the discussion of the relevant literature, the type of sociolinguistic variation targeted in the study, etc.) raised by the previous round of reviews. My immediate feeling is that not all of the points and requests were fully addressed, and that further revision may be needed to address especially the following issues: (1) the research questions and hypotheses are still not entirely clear, and could be streamlined further; (2) I find the logic of the study still hard to follow at times; (3) the discussion could still do a better job at discussing the limitation of the study and possible alternative interpretations of the results.

General issues:
1)      In general, the paper has a feeling of “unfinishedness” to it. This is especially true of the Introduction and General Discussion, but it also permeates the Methods and Results section. Readers of Language Learning that are not entirely familiar with the reviewed literature (like me) could benefit from a few more details on the studies that are presented (e.g., on p. 5 and 6). Expanding on some of the background literature and on the hypotheses and design of the current study, as well and working on the general cohesiveness of the narrative, would make the submission much stronger.

2)      I think that the entire Methods section (p. 10-17) is quite difficult to follow. Despite several rereads, I had to rely on the Methods section from Rácz, Hay, and Pierrehumbert (2017), in order to fully understand the procedure. I think that the authors should rework the methods section drawing from their 2017 paper, which does a much better job at explaining the experimental task. I like the procedure and I think the design is for the most part quite elegant, but it gets somehow penalized by the poor structure of the section. A (quite extensive) rewrite of the Methods section should easily solve the problem. As also pointed out by Reviewer 1 (first round of reviews), I feel that the authors could still be more explicit in how this study expands on their 2017 paper both methodologically and theoretically.

3)      APA-related issue: Figures and Tables are not referenced in the right order in the text. Either fix the text or change the order of pictures (e.g., Fig. 3 is mentioned before Fig. 1 and 2, see p. 11) and tables accordingly.

4)      Given that there is only one experiment in the study, I do not think we need both a Discussion and a General Discussion. Please merge the two sections together.

Design:
5)      I think it is problematic that diminutives and plurals were not represented in the material in equal measure. Plural suffixes were only tested on a subset of the participants because the diminutive is a more “common and iconic pattern that is easier to interpret visually” (I personally believe that the singular-plural distinction is also quite easy to represent visually). Unfortunately, this decision seems a bit a priori, and I cannot help but think that using an equal ratio of diminutive and plural suffixes would have made for a stronger design. I am aware that fixing this issue would require running additional experiments, and I do not think this should be the case here. However, a less painful option that the authors could consider is to remove the plural suffix trials from the data and only focus on the diminutives, as this would make for a cleaner presentation of both hypotheses and results. 

6)      I also have a slight issue with the visuals of the conversation partners (Fig. 3). It seems to me that the characters in the first set (row 1 and 2) are more visually homogeneous than characters in the second set (row 3 and 4). That is, while it is easy to categorize the characters in the top two rows as differing on three characteristics (gender, age, orientation), there is a lot more going on in the bottom rows (different hair color, different clothing, and in general a number of small details such as creases on dresses and buttons on shirts, which are not there in the first set). So, the bottom set is more visually clattered than the top, and I am wondering whether this may be affecting performance (which would explain e.g., the weaker effect of ethnicity). One way of addressing this problem would be to re-run the models that predict response accuracy based on the Levenshtein distance between images, but this time adding the different pictures as predictors in the model (could be either fixed or random effect; also note that this only works if the Levenshtein distance is calculated on the color version of the images (e.g., RGB values) rather than after reducing the images to grey scale values, since much of the “visual clutter” is driven by the colors, I think).

Issues with statistical modelling (pages 16-22):
Although the authors have in part addressed the comments from the first round of reviews (the analyses are now more consistent with the hypotheses of the study), some major issues remain:

1)      The specifications of the statistical models (both linear and binomial regressions) are not clearly stated in the text. Rather, the structures of the models are almost only inferable by looking at the output of the model presented in tables 4 and 6. When working with linear mixed-effects model, and especially when using the lme4 package in R, it is customary to report the full specification of the models that have been run, either in the form of a mathematical formula, or using R syntax. For instance, p. 17: “For the test model, we considered interactions of across-participant and within-participant predictors. Relevant random slopes were also tested”. Given what I have from p. 15 and Table 4 (across-participant predictors are participant Gender and Age, within-participant predictors are Cue[View, Gender, Ethnicity, Age], Pattern, and Familiarity), I imagine that the structure of the model must have been something along these lines: Correct ~ GenderP+AgeP+(Cue*Familiarity)+(1 | Participant): that is, accuracy is predicted by the main effect of across-participant variables and the interaction effects between Cue and Familiarity, with random intercepts for participants. However, this information is not provided to me, therefore I cannot be sure that this is indeed the correct model. Moreover, the text references testing “relevant random slopes” (i.e., 1 + ????? | Participant), but no information is provided on which variables given as random slopes for participants, and there is no way to infer them from the model output.

2)      Page 17: “We used goodness-of-fit testing (with a significance threshold of p < 0.05) and the Akaike Information Criterion for model selection and reported the best model”. I like the use of model selection, but we need to know which models have been tested, and what the outcome of the test was for the individual models.

3)      As the authors also point out on p. 16, count data are not normally distributed, nor are their residuals. I appreciate the authors effort to keep the modelling simple and clear, but using a linear regression here is not ideal and can possibly have generated spurious results. The authors should instead fit the data using a Poisson distribution with a log link function, which expresses the probability of count data (this is easily doable in lme4 using glmr() and specifying family as Poisson and link as log). Given that 24 was the minimum N of trials, it may even be an idea to rescale the count data, so that 24 = 0 (in this way the data would be counting the N of *additional* trials needed on top of the minimum possible N). Beware that using the log link will rescale the outcome variable, meaning that the Estimate values in the output table will not be in the original scale (0-1 probability) anymore (you can get back to the original scale using the inverted log function).

4)      This is probably the biggest issue with the paper: the statistical models reported in the paper have very little to none use when it comes to hypothesis testing. No p-values nor confidence intervals or effect size values are reported, and marginal effect plots are only reported for one specific contrast (Cue*Familiarity in one specific model (Fig. 6). Although I am sympathetic with the idea of moving away from null-hypothesis significance testing, we unfortunately cannot draw any conclusions about the hypotheses of the study from the reported data. Unless I am missing something, the authors base their conclusions exclusively on Estimate values (but we have no information about the size/significance of these effects) and on visual inspection of the plot (but these plots are based on the raw data, and not on the statistical models, and therefore give no information about the nature of the effects – plotting the fitted data would have made matters slightly better). The authors do mention the use of model selection (e.g., on p. 6: “… the gender effect seen in training is not supported by model comparison”), which can be used for hypothesis testing, but these results are not reported anywhere. Therefore, I am not sure of what to do of any of the results as they are currently reported. I would recommend that the authors report p-values for all predictor estimates, for instance by using the “lmerTest” package (Kuznetsova, Brockhoff, & Christensen, 2017). If the authors would rather use model comparison, then the different models (as well as the test results) should be reported explicitly (see point 2 above).

5)       As a consequence of the issues expressed in point 4, the paper in its current form does not conform to the Statistical Guidelines of the journal: neither confidence intervals nor effect size values are reported. This should of course be corrected.

6)      I am a bit puzzled by the inclusion of participant gender and age as fixed effects in the model, since the authors do not have any specific hypotheses about the possible effect of these variables on performance. If they do, then these hypotheses should be stated explicitly on page 15. If they, on the other hand, are only interested in controlling for gender and age differences in the sample, then I am quite convinced that it would suffice having participants as a random effect in the model (as it is already the case, if I understand the model structure correctly).

7)      It seems very likely that the length of training (N of trials needed by the participants to complete the training phase) would be a very strong predictor of performance in the test phase. The authors state this themselves on page 18: “A participant that finished training faster will be more accurate in test (est = -0.03, se = 0.0005, using binomial generalized linear regression)”. However, I cannot seem to find a trace of this main effect anywhere — at least not in Table 6, where I would expect it to be. Without this information, any effect of Cues and Familiarity may be irrelevant, since the effect of training may turn out to explain most of the variance in test performance. Please fix.

8)      Page 15: “Since we do assume that training is longer in certain across-participant conditions than others, we took every condition separately and then removed the slowest 2.5% based on training trial count threshold”. I do not think this is necessary when using regression models. I would suggest that the authors re-run the analyses without filtering out the slowest 2.5% and see whether they get different results.

9)      Page 19: “3. One, small group have learnt the rule but in reverse…”. Where is this information coming from? This does not seem to be the case by looking at Fig. 5 – there are a very few data points below 25%.

10)     Minor comment about Fig. 4 and 5: I like the use of the rug plot to show the raw data points on the y-axis, however it is quite uninformative in its current form, since a lot of the points are overlapping. Consider lowering the alpha value of the geom_rug() in ggplot in order to better show the amount of overlap between data points.

11)     Fig. 6: The lack of error bars makes it hard to determine the strength/significance of the difference between familiar and unfamiliar items in relation to Age and Ethnicity. Please fix.

12)     P. 15, second to last paragraph: Strictly speaking it is wrong to list training vs. test as a within-participant factor here, since you are modeling the two phases separately (i.e., considering the two phases as two separate experiments).

Minor issues:
1)      There are a couple of literal quotes in the Introduction, e.g. on p. 4 and 5. The authors should consider rephrasing these in their own words to make the text flow better.

2)      P. 3, top paragraph: “Non-linguistic contexts also play a crucial role in early…”. This phrase ends a bit abruptly.

3)      P. 7, third paragraph (“The mechanisms through … Chevrot & Foulkes, 2013) is a bit obscure, please expand if relevant, otherwise delete.

4)      P. 9, The Current Study, first paragraph (“Previous research … experimental setting”): References to previous research should appear here.

5)      P. 10, second to last paragraph (“Such allomorphies are common across languages … Hungarian”): It would be nice with some examples here, especially for people that do not work with allomorphy.

6)      P. 11, second to last sentence (“It is easy…”): awkward phrasing, please rewrite.

7)      P. 13: “Choosing a suffix depends on whether … they face is irrelevant” is redundant, consider deleting.

8)      P. 14: “The platform has been …  Berinsky, Huber, & Lenz, 2012” can be deleted, people have now been using Amazon Mechanical Turk in research for years (I believe that this was probably added in response to a comment by Reviewer 2).

9)      Same page, “A participant who gets … servers might be unreliable”: also unnecessary, please delete.

10)     P. 15, “0.72*(24^2.07)~518 trials”: where is this coming from? What are 0.72 and 2.07? I must be missing something here.

11)     P. 16, top paragraph (“Figure 3 … different individuals”): This could be removed from here and added as caption to Table 2 instead.

12)     P. 19, top, “However, participants are not normally distributed within each condition”): You mean that average scores are not normally distributed? Were you expecting them to be?

13)     P. 22, line 14: “socially irrelevant” -> “less socially relevant” (see point 3 under “General issues”).


Reviewer: 3
Recommendation: Minor Revision
Comments to the Author:

It was very good to see how engaged the authors were with the feedback they received and how they tried to implement it. Many of the issues in the previous version of the paper have been dealt with and this version is on the whole easier to follow. 
I think that there may still be a little bit of work guiding the reader at the start however: I understand that it's normal to discuss the literature review before the details of the study itself, but I think the introduction might cover them slightly more as otherwise it's not immediately clear to the reader how some of the literature is going to be relevant. 
The results section is clearer, but there are still a lot of tests one after the other and in places I wasn't sure what was being tested and why anymore, so here too a little bit more guidance would be good. 
There are still a few typos and sentences that don't read clearly here and there (e.g. p 4 line 3, it should be a comma, not a full stop ... if not. do our prior...) and the tenses go back and forth in places between past and present (mostly where I'd expect it to stick to the past, e.g. p 14 where the participants are being discussed)
A couple minor points:
- p .11 figure 3 is mentioned before figure 1 - should the numbering be changed? 
- p 23 French marking of the gender of the addressee for possession - maybe include an example, I couldn't work out what this would be (ton, ta? but they're not marked according to the addressee's gender)