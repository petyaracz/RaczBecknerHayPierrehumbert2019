Dear Pavel

We would like to submit the revised version of our ms ID 18-ES-2560.R1, titled `Not all indexical cues are equal:  Differential sensitivity to dimensions of indexical meaning in an artificial language' to Language Learning.

The word "social" was changed to "indexical" in the title. This is in line with revisions in the previous round, emphasising that the paper considers distinctions that are too simple to be considered properly "social".

In this round, in response to reviewer comments, we have reworked the introductory sections of the paper, completely rewritten the methods section, and reran the statistical analyses and correspondingly rewritten the results section as well.

We removed our "research questions" to focus on the main hypotheses, added a section to spell out the rationale of the current study, and merged the discussion and general discussion sections.

Changes in the revised text are in blue -- a blue section title indicates that a complete section has been entirely rewritten.

Below, we respond to your point-by-point summary of the reviews and then go on to respond to the reviewers in turn.

> 1. As discussed by all reviewers, improve the flow and the logic of the writing in the introductory section of your manuscript and especially with respect to your research questions. The reviewers indicated that (a) the literature review did not prepare the reader adequately to understand your study, (b) your research questions were unclear, and (c) the overall logic of literature review was hard to follow.

We changed the introductory and background sections in three major ways. First, we set up the previous and the current study immediately after the starting paragraph to provide context to what follows. Second, we removed the "research questions" and instead set up the introduction + background to lead up to the rationale for the current study and, subsequently, to the main hypotheses. Third, we wrote a number of linking paragraphs in the background section. These (hopefully) spell out why we need to overview specific domains of category learning and language variation and how results from these fields inform our study.

> 2. As particularly discussed by Reviewers 1 and 5, please ensure that the manuscript reports full methods, materials, and procedure information that would make it a standalone publication and would not require the reader to first consult your previously published work. And again, do provide a clear, coherent account of how the current dataset extends and builds on your previous publication. This information should ideally be used to motivate the current study.

We now discuss the previous study three times: First, we set it up immediately at the beginning to motivate the current study. Second, we discuss its results in detail at the end of the background section to segue into the rationale for our current study. Third, we return to it in the Discussion in order to highlight what the conversation on contextual language learning can gain from the present study.

We were rather alarmed that Reviewer 5 had to revisit the 2017 paper to understand the design of the current one. This was clearly not our intent. We now used the methods section of the 2017 paper as a basis to remodel our methods section.

> 3. Address carefully the Design issues raised by Reviewer 5. I will leave it up to you whether you would wish to remove any data from analysis (point 5 in this reviewer’s feedback), but I strongly encourage you to consider using Levenshtein’s distance between images as a predictor in your analyses (point 6 in this reviewer’s feedback).

We adopted every single suggestion by Reviewer 5 -- we discuss these changes one by one in our reply to this reviewer.

> 4. Most importantly, you must address all statistical/analytical concerns expressed by Reviewer 5 (under Issues with statistical modelling). I find all of these concerns reasonable, and would like to reiterate that reporting effect size values and confidence intervals is mandatory for us (point 5 under statistical/analytical concerns by Reviewer 5).

Model comparisons are now reported in the methods section and estimated 95% confidence intervals are reported in the results section. We hope that this framing is now sufficient to provide enough information to the reader without resorting to p values. 

The data analysis section might be overly verbose at this point. For each model, it lists all relevant fits along with the statistics of how well they fit the data. One alternative could be to shorten this by reporting on how comparisons were made and what the precise criteria were for picking a best model. Another alternative would be to shorten the data analysis section this way and report all the comparisons in an online-only appendix. We would leave this for the Editor to decide.

> 5. Finally, address all remaining issues by all reviewers.

Please find below.

Reviewer: 1
Recommendation: Minor Revision
Comments to the Author:

> My first issue with the introduction is that the first research question (“Can we reliably associate any non-linguistic context whatsoever with linguistic constructions?”) still feels too broad considering the question the experiment answers. What exactly is the answer? Do we conclude that for 18% of participants, at least, the answer is yes? (But then, what if there are harder contexts to learn than orientation?) Or do we conclude that, because most participants failed to learn the association with orientation, that it can’t be reliably associated with linguistic constructions? (But then, most participants failed on gender too, and we already know that that can be associated with linguistic constructions.) The second part of the same question (“If not, do our prior expectations regarding what contexts are generally socially relevant play into whether such an association can be established?”)  also seems slightly problematic. I’d agree that participants presumably arrive with prior expectations as to what contexts are generally socially relevant, but that isn’t actually measured here; it’s simply inferred based on what humans seem to associate linguistic constructions to in natural language. The hypotheses given on page 10 seem a much better way to set up the goals of the study.

The reviewer has a point here. Our intention was to set up a broad field of interest using research questions and then narrow this down using hypotheses. It seems that the research questions do not particularly aid in setting up the broad field of interest and instead confuse readers. 

Instead, we now start the paper with the current study, and then very explicitly state that, in order for the reader to follow why this is interesting or how this works, we need to set up a number of previous results from specific domains. We then do this, in a way that is more verbose. This segues into a new section, the rationale for the current study, which concludes with the hypotheses. We explicitly revisit the hypotheses in the results section and the discussion.

> My other issue is more minor and concerned with how the introduction flows. It’s generally much better, but could still be improved. Two examples stand out. First, the section on contextual learning segues from discussion of context aiding memory to context aiding prediction, to the involvement of context in learning, to the role of context in processing. That’s fine in itself, but the transitions are not quite seamless. For instance, it’s not at all clear in the text how the Qian et al. (2014) study is really a non-linguistic equivalent of the immediately preceding studies. The sociolinguistic learning section has a related but slightly different problem: It feels like a somewhat disjointed list of studies.

This reviewer is not alone in finding the introduction disjointed. We wrote a number of linking paragraphs that hopefully clarify why we want to talk about a certain thing and how that relates to previous things. We also hope that, as a result, the reader will not feel that details are missing, because the new flow makes the levels of resolution clearer. For instance, we expanded the sociolinguistic learning section to explain how, in our narrative, one study follows from the other. The section now sets up more clearly that broad contextual variation can be learned in the lab, and that variation based on gender is picked up in these tasks by both children and adults. This leads us to our 2017 study, which, in turn, leads to our present study.

> The Method and Results sections continue to suffer from problems with clarity.  Part of the problem, I think, is that it feels as if there are two many paragraph breaks, which contributes to a disjointed feel. But there are other problems of unclarity. For instance, on page 10, the conversation partner is introduced in a way that takes the reader by surprise. It would be clearer if the paragraph said something like, “In the first, training phase, a participant has to progress on a path, learning a simple artificial language from [IN ITALICS] conversation partners met along the way. In this language, suffixes that represent a grammatical relation (either the diminutive or the plural) are contextually cued: they depend on the conversation partner, present in each trial.” (Another issue here, incidentally – what precisely constitutes a trial?) There are a few cases like this. I feel as if the Method section would benefit from being reread by someone entirely unfamiliar with the study.  The same problems continue in the Results section, which I found hard to follow. I would suggest the same remedy.

We have completely rewritten the Methods and Results sections. The Methods section now starts with a description of one specific experimental setup, ignoring the rest of the details, which are added later. The results section is now simplified -- a large amount of detail is moved to the data analysis section, and the main results and how these survive additional scrutiny are spelt out more clearly at the end.

> Minor issues (many of which contribute to clarity issues mentioned above):
> 1. There is a formatting error in the abstract (? instead of, I assume, dashes)

Corrected.

> 2. The present tense should be replaced by the past tense in many places throughout the manuscript. Its use in reporting published work (e.g., “Docherty, Langstrof, and Foulkes (2013) investigate…”) is common but explicitly discouraged in APA style.  Its use in describing experimental method or reporting results is a little odder and slightly jarring.

We re-tensed the paper to simple past. The one exception is the first description of the experiment, where the past tense seemed overly distracting.

> 3. Page 6: “Speakers of different dialects will focus on and learn different linguistic details (Cohn, Ham, & Podesva, 1999), and speaker awareness of contextual information on all levels can be very imprecise”. This sentence seems to require a “but” not an “and”, as there appears to be a contrast between the two halves. The “and” thus creates a slightly jarring effect.

The reviewer is right that this is not quite a logical relation: speakers learn different things. at the same time, speakers are imprecise. We corrected this to "while speaker awareness..."

> 4. Page 6: “While these factors will have complex social and linguistic representations, they will remain robust and socially salient”. Is there a source for this? 

Upon revisiting, this sentence feels like a red herring; in the end, all factors have complex social and linguistic representations, while the previous sentence cites sources on the salience of these specific factors. We removed the sentence.

> 5. Page 9: A conjunction is missing at least twice (in the first sentence and in the sentence beginning “It utilises…”)

Corrected.

> 6. Page 9: “adults […] discard contexts that are deemed irrelevant.” By whom? By the adults themselves? I’m also not sure “deem” is the right term here, since (to me at least) it implies conscious deliberation.

This is a good point -- we removed "deem" (as we make no claims about deeming in the preceding literature review).

> 7. Page 10: The distinction between “socially salient” and “accidental” seems like a category error. Can’t accidental things be socially salient (and can’t non-accidental things be insalient)?

This is indeed unclear. We replaced "accidental" with "irrelevant".

> 8. Why is Figure 3 referenced before Figure 1?

Corrected.

> 9. Page 12: “we repeated two conditions using plural instead of diminutive as the morphological category.” This needs to be clarified! “Repeat” can mean a lot of things. On a related note, the asterisk in Table 2 needs to be explained in the caption.

We added a clarificatory sentence here: "we replicated two conditions using plural instead of diminutive as the morphological category. In these replicated conditions, participants perform the exact same task except that diminutive images are replaced with plural ones." Also clarified the caption.

> 10. Page 15: “Learning extends to generalisation” seems an odd way to express this.

True. All we need to claim is that learning "is followed by" generalisation, so we corrected to this phrasing.

> 11. Page 18: “Training is faster with age, ethnicity, and the fastest with gender.” There seems to be a missing conjunction here again.

This sentence has been removed during the ms' reorganisation.

> 12. Page 18: “it seems that ignoring the view cue is about as difficult as ignoring the gender cue. I think this would be clearer if something were added along the lines of, “In spite of the differences between the different cues when they were main cues…”

This sentence has been removed during the ms' reorganisation. Hopefully the reworked Results section is easier to follow.

> 13. The reasoning on pages 21–22 starting with “Second, the overall…” is hard to follow and could do with being clarified.

This sentence, too, has been removed during the ms' reorganisation.

> 14. Page 22: I think  “derivative morphology” should be “derivational morphology”. I wonder if perhaps this distinction isn’t in danger of being language-specific. I am unaware of any language in which plural suffixes are derivational and diminutives are inflectional, but this may simply reflect my ignorance. In Welsh, for instance, equivalent forms to passive participles in other languages are formed by a clearly derivational affix, which seems to surprise some people. There are also languages that don’t have inflectional number marking; do some of these have derivational markers used in some cases?
15. Page 23: “for example, in French, incorrect marking of the gender of the addressee in a possessive construction will lead to incomprehension.” Perhaps I am misunderstanding what is being claimed about French, but what I imagine from this example is the contrast between “ton [masc.] cheval” and “ta [f.] voiture”; but this distinction depends on the gender of the possessed, not the addressee.

We believe that a major take-away from the Reviewer's point here is that any discussions of morphology will remain tenuous at best, given that the study itself barely touches upon typological questions. What we want to ultimately say is that the task works with at least two different morphological contrasts (not only with the diminutive but also with the plural), much like what we find in our 2017 study. So we removed the discussion of inflectional/derivational morphology.

> 16. Christiansen and Kirby (2003) was written before the experimental turn in language evolution, and thus seems clearly the wrong citation on page 26. The authors might like to consider (for instance): 
> * Scott-Phillips, Thomas C., and Simon Kirby. "Language evolution in the laboratory." Trends in cognitive sciences 14.9 (2010): 411-417.
> * Roberts, Gareth. "The linguist’s Drosophila: Experiments in language change." Linguistics Vanguard 3.1 (2017).

We removed the Christiansen and Kirby citation and instead cite these two works (as we should have in the first place).

Reviewer: 5
Recommendation: Major Revision
Comments to the Author:

> Since I am not an expert in sociolinguistic, I will leave it to the other reviewer(s) to comment on whether the revised manuscript addresses the theoretical issues (i.e., the discussion of the relevant literature, the type of sociolinguistic variation targeted in the study, etc.) raised by the previous round of reviews. My immediate feeling is that not all of the points and requests were fully addressed, and that further revision may be needed to address especially the following issues: (1) the research questions and hypotheses are still not entirely clear, and could be streamlined further; (2) I find the logic of the study still hard to follow at times; (3) the discussion could still do a better job at discussing the limitation of the study and possible alternative interpretations of the results.

We thank the Reviewer for their scrutiny. We adopted all their suggestions and discuss the resulting changes in turn.

> 1)      In general, the paper has a feeling of “unfinishedness” to it. This is especially true of the Introduction and General Discussion, but it also permeates the Methods and Results section. Readers of Language Learning that are not entirely familiar with the reviewed literature (like me) could benefit from a few more details on the studies that are presented (e.g., on p. 5 and 6). Expanding on some of the background literature and on the hypotheses and design of the current study, as well and working on the general cohesiveness of the narrative, would make the submission much stronger.

Following similar comments from all reviewers in this round, the ms has been completely reworked up to the methods section. Now, it introduces the study and its 2017 precedent immediately, explains which literature has to be discussed to set up the premises for the study, provides more links between the various studies to show how they inform the same questions, and adds a rationale for the current study, leading up to the hypotheses tested. We also reorganised the Discussion and the General Discussion, which now start with a summary of the results in the context of the starting hypotheses, follows with how this connects to the 2017 study, and then goes on to speculate a bit on how the results should be interpreted. While we think that speculation has its place in a discussion, we have to admit that the lack of structure in the last version of this ms made speculation overly salient and rampant. Hopefully the rewrites rectify this issue.

> 2)      I think that the entire Methods section (p. 10-17) is quite difficult to follow. Despite several rereads, I had to rely on the Methods section from Rácz, Hay, and Pierrehumbert (2017), in order to fully understand the procedure. I think that the authors should rework the methods section drawing from their 2017 paper, which does a much better job at explaining the experimental task. I like the procedure and I think the design is for the most part quite elegant, but it gets somehow penalized by the poor structure of the section. A (quite extensive) rewrite of the Methods section should easily solve the problem. As also pointed out by Reviewer 1 (first round of reviews), I feel that the authors could still be more explicit in how this study expands on their 2017 paper both methodologically and theoretically.

We found it alarming that the Reviewer had to go back to the 2017 paper to understand what we are doing here. This clearly was not our intent. We have rewritten considerable parts of the methods section. It now starts by setting up a singular case of the design (gender versus spatial orientation), and all the additional details (the use of additional conversation partners, the precise materials, etc) are set up later. We hope that this makes the design easier to follow.

> 3)      APA-related issue: Figures and Tables are not referenced in the right order in the text. Either fix the text or change the order of pictures (e.g., Fig. 3 is mentioned before Fig. 1 and 2, see p. 11) and tables accordingly.

Corrected.

> 4)      Given that there is only one experiment in the study, I do not think we need both a Discussion and a General Discussion. Please merge the two sections together.

Corrected. We clipped the "discussion" and merged it with the "general discussion"

> Design:
5)      I think it is problematic that diminutives and plurals were not represented in the material in equal measure. Plural suffixes were only tested on a subset of the participants because the diminutive is a more “common and iconic pattern that is easier to interpret visually” (I personally believe that the singular-plural distinction is also quite easy to represent visually). Unfortunately, this decision seems a bit a priori, and I cannot help but think that using an equal ratio of diminutive and plural suffixes would have made for a stronger design. I am aware that fixing this issue would require running additional experiments, and I do not think this should be the case here. However, a less painful option that the authors could consider is to remove the plural suffix trials from the data and only focus on the diminutives, as this would make for a cleaner presentation of both hypotheses and results. 

We followed the Reviewer's suggestion and now only report the diminutive data in detail in the results section. 

We make a separate point about plurals versus diminutives: In our 2017 paper, we show that participant accuracy across the gender / view distinction is similar with plural and with diminutive suffixes. Here we point to this result and add that the same is the case for the gender / ethnicity distinction.

In the data analysis section, we provide the model comparison that supports this conclusion.

> 6)      I also have a slight issue with the visuals of the conversation partners (Fig. 3). It seems to me that the characters in the first set (row 1 and 2) are more visually homogeneous than characters in the second set (row 3 and 4). That is, while it is easy to categorize the characters in the top two rows as differing on three characteristics (gender, age, orientation), there is a lot more going on in the bottom rows (different hair color, different clothing, and in general a number of small details such as creases on dresses and buttons on shirts, which are not there in the first set). So, the bottom set is more visually clattered than the top, and I am wondering whether this may be affecting performance (which would explain e.g., the weaker effect of ethnicity). One way of addressing this problem would be to re-run the models that predict response accuracy based on the Levenshtein distance between images, but this time adding the different pictures as predictors in the model (could be either fixed or random effect; also note that this only works if the Levenshtein distance is calculated on the color version of the images (e.g., RGB values) rather than after reducing the images to grey scale values, since much of the “visual clutter” is driven by the colors, I think).

We reran the comparison of perceptual versus conceptual distance using the model suggested by the reviewer. We also moved the entire discussion of distances to the data analysis section and only point to it towards the end of the results section to reduce clutter. We provide the model comparison that supports our conclusion, namely that conceptual distance outweights perceptual distance in accounting for participant success in the test trials.

We respectfully disagree with the reviewer's suggestion about using coloured images as a basis of comparison. We would bring two arguments for this. First, hosting the setup on Mechanical Turk means that we have no control over the "equipment": participants' screens can look like anything, and the resulting colour spectra are likely highly variable. What will then remain constant is the colour contrasts. Second, the hue distinctions are fairly visible in the black and white images as well (perhaps even more so). These aspects together incline us to use black and white distances.

> Issues with statistical modelling (pages 16-22):
Although the authors have in part addressed the comments from the first round of reviews (the analyses are now more consistent with the hypotheses of the study), some major issues remain:

> 1)      The specifications of the statistical models (both linear and binomial regressions) are not clearly stated in the text. Rather, the structures of the models are almost only inferable by looking at the output of the model presented in tables 4 and 6. When working with linear mixed-effects model, and especially when using the lme4 package in R, it is customary to report the full specification of the models that have been run, either in the form of a mathematical formula, or using R syntax. For instance, p. 17: “For the test model, we considered interactions of across-participant and within-participant predictors. Relevant random slopes were also tested”. Given what I have from p. 15 and Table 4 (across-participant predictors are participant Gender and Age, within-participant predictors are Cue[View, Gender, Ethnicity, Age], Pattern, and Familiarity), I imagine that the structure of the model must have been something along these lines: Correct ~ GenderP+AgeP+(Cue*Familiarity)+(1 | Participant): that is, accuracy is predicted by the main effect of across-participant variables and the interaction effects between Cue and Familiarity, with random intercepts for participants. However, this information is not provided to me, therefore I cannot be sure that this is indeed the correct model. Moreover, the text references testing “relevant random slopes” (i.e., 1 + ????? | Participant), but no information is provided on which variables given as random slopes for participants, and there is no way to infer them from the model output.

The Reviewer raises a number of important issues in points 1-5 that we respond to under 5.

> 2)      Page 17: “We used goodness-of-fit testing (with a significance threshold of p < 0.05) and the Akaike Information Criterion for model selection and reported the best model”. I like the use of model selection, but we need to know which models have been tested, and what the outcome of the test was for the individual models.

> 3)      As the authors also point out on p. 16, count data are not normally distributed, nor are their residuals. I appreciate the authors effort to keep the modelling simple and clear, but using a linear regression here is not ideal and can possibly have generated spurious results. The authors should instead fit the data using a Poisson distribution with a log link function, which expresses the probability of count data (this is easily doable in lme4 using glmr() and specifying family as Poisson and link as log). Given that 24 was the minimum N of trials, it may even be an idea to rescale the count data, so that 24 = 0 (in this way the data would be counting the N of *additional* trials needed on top of the minimum possible N). Beware that using the log link will rescale the outcome variable, meaning that the Estimate values in the output table will not be in the original scale (0-1 probability) anymore (you can get back to the original scale using the inverted log function).

> 4)      This is probably the biggest issue with the paper: the statistical models reported in the paper have very little to none use when it comes to hypothesis testing. No p-values nor confidence intervals or effect size values are reported, and marginal effect plots are only reported for one specific contrast (Cue*Familiarity in one specific model (Fig. 6). Although I am sympathetic with the idea of moving away from null-hypothesis significance testing, we unfortunately cannot draw any conclusions about the hypotheses of the study from the reported data. Unless I am missing something, the authors base their conclusions exclusively on Estimate values (but we have no information about the size/significance of these effects) and on visual inspection of the plot (but these plots are based on the raw data, and not on the statistical models, and therefore give no information about the nature of the effects – plotting the fitted data would have made matters slightly better). The authors do mention the use of model selection (e.g., on p. 6: “… the gender effect seen in training is not supported by model comparison”), which can be used for hypothesis testing, but these results are not reported anywhere. Therefore, I am not sure of what to do of any of the results as they are currently reported. I would recommend that the authors report p-values for all predictor estimates, for instance by using the “lmerTest” package (Kuznetsova, Brockhoff, & Christensen, 2017). If the authors would rather use model comparison, then the different models (as well as the test results) should be reported explicitly (see point 2 above).

> 5)       As a consequence of the issues expressed in point 4, the paper in its current form does not conform to the Statistical Guidelines of the journal: neither confidence intervals nor effect size values are reported. This should of course be corrected.

We considerably reworked the data analysis and results sections in response to the above comments. The changes are as follows:

- For each model discussed in the results section, the data analysis section now lists the specific model formulae (along with random effects) fit in the process of model comparison, as well as the models' goodness-of-fit statistics. So, for instance: in the data analysis, we say that in order to see whether X has an effect, we tested (i) "outcome ~ X + Y" and (ii) "outcome ~ Y". These models have the following goodness-of-fit statistics. This suggests that (i) provides a significantly better fit. This is what we report in the results. In the results, we report (i) and provide 95% CI-s for X and Y. In other cases, we do not report the model in the results in detail, we only point to it in the results. (along the logic of "X is not relevant. see data analysis.")
- Beside the formulae, outcomes and predictors are spelt out in the running text in the data analysis section.
- We removed a separate discussion of training results from the paper. This might seem a major change in how results are presented, but the training results are overall in line with the test results. Instead, we now consider training success in modelling the test data (see below).
- Where we report estimates in the results section, we now provide 95% Wald confidence intervals and give a relatively simple explanation on how they should be interpreted. Hopefully this brings us in line with the statistical guidelines of the journal without reporting p values for predictor estimates.

> 6)      I am a bit puzzled by the inclusion of participant gender and age as fixed effects in the model, since the authors do not have any specific hypotheses about the possible effect of these variables on performance. If they do, then these hypotheses should be stated explicitly on page 15. If they, on the other hand, are only interested in controlling for gender and age differences in the sample, then I am quite convinced that it would suffice having participants as a random effect in the model (as it is already the case, if I understand the model structure correctly).

The Reviewer is right. We by and large did not anticipate gender or age effects and struggled considerably in accounting for them. It is entirely likely that participant age and gender are very relevant aspects of the learning process investigated in tasks of this type, but, if that is the case, this should perhaps be assigned to future research.

> 7)      It seems very likely that the length of training (N of trials needed by the participants to complete the training phase) would be a very strong predictor of performance in the test phase. The authors state this themselves on page 18: “A participant that finished training faster will be more accurate in test (est = -0.03, se = 0.0005, using binomial generalized linear regression)”. However, I cannot seem to find a trace of this main effect anywhere — at least not in Table 6, where I would expect it to be. Without this information, any effect of Cues and Familiarity may be irrelevant, since the effect of training may turn out to explain most of the variance in test performance. Please fix.

We now include training trial counts in our model of the test data, as spelt out in the data analysis section. Participants who are faster in training are also better in test, but the effects of cue type and familiarity remain relevant beyond this. Of course, cue type in training and participant speed in training are strongly correlated, but the variance inflation factors of the model are not high enough for us to worry that our results are artefacts of model fitting.

> 8)      Page 15: “Since we do assume that training is longer in certain across-participant conditions than others, we took every condition separately and then removed the slowest 2.5% based on training trial count threshold”. I do not think this is necessary when using regression models. I would suggest that the authors re-run the analyses without filtering out the slowest 2.5% and see whether they get different results.

If we rerun the best model of the test data reported in the paper using all participants, we find that the results remain very similar -- the z values are all in the same ballpark. 

Our reason for excluding outliers is predominantly ontological: given the paradigm (Mechanical Turk), it is clear to us that not all participants paid the same amount of attention, and while our cutoff is an arbitrary (albeit established) one, it allows us to trim those who tried the least. This is the justification for using the same threshold in our 2017 study. To put it in another way: it is true that no participant takes anywhere as long as they would if they picked training trial responses truly at random, but it is still likely that some of them got past training by poor rote learning and sheer force of will, and our outlier thershold helps us remove some of them.

> 9)      Page 19: “3. One, small group have learnt the rule but in reverse…”. Where is this information coming from? This does not seem to be the case by looking at Fig. 5 – there are a very few data points below 25%.

This is a distracting comment that does not really build up anything, so we removed it. Incidentally, there are people who seem to have learnt the rule in reverse, and they are now visible in the figures (see next point), but the fact that they exist is probably statistically not remarkable.

> 10)     Minor comment about Fig. 4 and 5: I like the use of the rug plot to show the raw data points on the y-axis, however it is quite uninformative in its current form, since a lot of the points are overlapping. Consider lowering the alpha value of the geom_rug() in ggplot in order to better show the amount of overlap between data points.

We reworked the plots so that they jitter participants in the violin of the given cue that they trained with. The plots now show both distribution of averages and proportions of participants who "figured it out" versus those who keep guessing in test.

> 11)     Fig. 6: The lack of error bars makes it hard to determine the strength/significance of the difference between familiar and unfamiliar items in relation to Age and Ethnicity. Please fix.

We reworked this plot as well, showing changes for each individual between familiar and novel conversation partners. In addition, we now report confidence intervals for these interactions in the main model.

> 12)     P. 15, second to last paragraph: Strictly speaking it is wrong to list training vs. test as a within-participant factor here, since you are modeling the two phases separately (i.e., considering the two phases as two separate experiments).

This is true. Corrected.

> Minor issues:
> 1)      There are a couple of literal quotes in the Introduction, e.g. on p. 4 and 5. The authors should consider rephrasing these in their own words to make the text flow better.

We kept one literal quote -- here we use a side quote that is not the main conclusion of a paper in a somewhat polemic way, and the verbatim reflects that. We rephrased the others.

> 2)      P. 3, top paragraph: “Non-linguistic contexts also play a crucial role in early…”. This phrase ends a bit abruptly.

Rephrased to "Non-linguistic contexts interact with other aspects of language use: they play a crucial role in early word learning..."

> 3)      P. 7, third paragraph (“The mechanisms through … Chevrot & Foulkes, 2013) is a bit obscure, please expand if relevant, otherwise delete.

This we think is an important point, so we expanded it further: "Indeed, modern theories of the mental lexicon, the storage of linguistic forms, tend to argue that non-linguistic and linguistic contextual information plays a crucial role in how forms are stored and processed, with effects on a range of phenomena from speech perception (Johnson 1997) to priming (De Vaab et al 2007)."

> 4)      P. 9, The Current Study, first paragraph (“Previous research … experimental setting”): References to previous research should appear here.

We now add citations to this paragraph that cross-reference it with work discussed in the previous section.

> 5)      P. 10, second to last paragraph (“Such allomorphies are common across languages … Hungarian”): It would be nice with some examples here, especially for people that do not work with allomorphy.

We reconsidered the discussion of types of allomorphy and came to the conclusion that any discussions of morphology here will remain tenuous at best, given that the study itself barely touches upon typological questions. What we want to ultimately say is that the task works with at least two different morphological contrasts (not only with the diminutive but also with the plural), much like what we find in our 2017 study. So we removed the discussion of morphology.

> 6)      P. 11, second to last sentence (“It is easy…”): awkward phrasing, please rewrite.

We rewrote this section, making the sentence disappear.

> 7)      P. 13: “Choosing a suffix depends on whether … they face is irrelevant” is redundant, consider deleting.

Corrected -- removed the sentence.

> 8)      P. 14: “The platform has been …  Berinsky, Huber, & Lenz, 2012” can be deleted, people have now been using Amazon Mechanical Turk in research for years (I believe that this was probably added in response to a comment by Reviewer 2).

To us, it seems that reader reactions to AMT data are bimodal. Some take it as a perfectly acceptable design decision, while others are more wary. Clearly, Reviewer 5 belongs in the former, Reviewer 2 in the latter category. For the wary reader, we think it is good to include a few references of this sort, if only to show that their epistemological concerns are shared by the authors and that a substantial body of literature exists that investigates precisely these concerns.

> 9)      Same page, “A participant who gets … servers might be unreliable”: also unnecessary, please delete.

Removed.

> 10)     P. 15, “0.72*(24^2.07)~518 trials”: where is this coming from? What are 0.72 and 2.07? I must be missing something here.

We agree that this is distracting, and expanding it would distract further. The point we want to make here is that we checked how long it takes to finish training guessing by the use of simulations, and we now say this in the test. 

> 11)     P. 16, top paragraph (“Figure 3 … different individuals”): This could be removed from here and added as caption to Table 2 instead.

Edited.

> 12)     P. 19, top, “However, participants are not normally distributed within each condition”): You mean that average scores are not normally distributed? Were you expecting them to be?

This was a clunky sentence and we removed it during the rewriting of this section. We were in fact surprised that participant test accuracy is so clearly bimodal, especially given that training trial counts are much more normally distributed. We now discuss participant distributions in test more clearly in the results section.

> 13)     P. 22, line 14: “socially irrelevant” -> “less socially relevant” (see point 3 under “General issues”).

Corrected.

Reviewer: 3
Recommendation: Minor Revision
Comments to the Author:

> I think that there may still be a little bit of work guiding the reader at the start however: I understand that it's normal to discuss the literature review before the details of the study itself, but I think the introduction might cover them slightly more as otherwise it's not immediately clear to the reader how some of the literature is going to be relevant.

We reorganised the sections leading up to the Methods. We now set up the current study right at the beginning, then spell out what aspects of human contextual learning need to be discussed to lead up to the hypotheses. Then we review the literature, with added linking paragraphs to explain how the various results belong together. Finally, we lead up to work on contextual language learing, our 2017 study, and how the current paper expands on that study, leading to the hypotheses. 

> The results section is clearer, but there are still a lot of tests one after the other and in places I wasn't sure what was being tested and why anymore, so here too a little bit more guidance would be good. 

We rewrote the data analysis and results sections. A lot of detail has been moved to the data analysis section. The results section is more terse on certain details that are less relevant. It is also more repetitive. Hopefully this helps bringing the main points of the paper across.

> There are still a few typos and sentences that don't read clearly here and there (e.g. p 4 line 3, it should be a comma, not a full stop ... if not. do our prior...) and the tenses go back and forth in places between past and present (mostly where I'd expect it to stick to the past, e.g. p 14 where the participants are being discussed)

We went through the paper and enforced the past tense, as per APA guidelines. The one exception is the first description of the experiment, where the past tense seemed overly distracting. 

> A couple minor points:
> - p .11 figure 3 is mentioned before figure 1 - should the numbering be changed? 

Corrected.

> - p 23 French marking of the gender of the addressee for possession - maybe include an example, I couldn't work out what this would be (ton, ta? but they're not marked according to the addressee's gender)

This example was not set up correctly: we replaced it with an example of French adjectives, which are marked by the gender of the modified nouns (contrasting "Je suis désolé" and "Je suis désolée"). 